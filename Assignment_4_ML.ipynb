{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####Q1. Write a Python program to scrape all available books from the website(https://books.toscrape.com/) Books to Scrape – a live site built for practicing scraping (safe,legal, no anti-bot). For each book, extract the following details:\n",
        "1. Title\n",
        "2. Price\n",
        "3. Availability (In stock / Out of stock)\n",
        "4. Star Rating (One, Two, Three, Four, Five)\n",
        "\n",
        "*Store the scraped results into a Pandas DataFrame and export them to a CSV file named books.csv.*\n",
        "\n",
        "(Note: Use the requests library to fetch the HTML page. Use BeautifulSoup to parse and extract\n",
        "book details and handle pagination so that books from all pages are scraped)"
      ],
      "metadata": {
        "id": "2GiK2ZD9L7jN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "qQBJCRY8LzFz",
        "outputId": "43da7016-b53c-4122-abbe-297297b6a498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching page 51: 404 Client Error: Not Found for url: https://books.toscrape.com/catalogue/page-51.html\n",
            "Scraping complete. Data saved to books.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                   Title    Price Availability Star Rating\n",
              "0                   A Light in the Attic  Â£51.77     In stock       Three\n",
              "1                     Tipping the Velvet  Â£53.74     In stock         One\n",
              "2                             Soumission  Â£50.10     In stock         One\n",
              "3                          Sharp Objects  Â£47.82     In stock        Four\n",
              "4  Sapiens: A Brief History of Humankind  Â£54.23     In stock        Five"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e111c70-5494-4f87-9427-a17e3b7b370e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Price</th>\n",
              "      <th>Availability</th>\n",
              "      <th>Star Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A Light in the Attic</td>\n",
              "      <td>Â£51.77</td>\n",
              "      <td>In stock</td>\n",
              "      <td>Three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tipping the Velvet</td>\n",
              "      <td>Â£53.74</td>\n",
              "      <td>In stock</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Soumission</td>\n",
              "      <td>Â£50.10</td>\n",
              "      <td>In stock</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sharp Objects</td>\n",
              "      <td>Â£47.82</td>\n",
              "      <td>In stock</td>\n",
              "      <td>Four</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sapiens: A Brief History of Humankind</td>\n",
              "      <td>Â£54.23</td>\n",
              "      <td>In stock</td>\n",
              "      <td>Five</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e111c70-5494-4f87-9427-a17e3b7b370e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e111c70-5494-4f87-9427-a17e3b7b370e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e111c70-5494-4f87-9427-a17e3b7b370e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ab4c1f6f-6913-428a-9ea7-2ee7f091b6cb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab4c1f6f-6913-428a-9ea7-2ee7f091b6cb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ab4c1f6f-6913-428a-9ea7-2ee7f091b6cb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Tipping the Velvet\",\n          \"Sapiens: A Brief History of Humankind\",\n          \"Soumission\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u00c2\\u00a353.74\",\n          \"\\u00c2\\u00a354.23\",\n          \"\\u00c2\\u00a350.10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Availability\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"In stock\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Star Rating\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"One\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_books():\n",
        "    base_url = \"https://books.toscrape.com/\"\n",
        "    all_books_data = []\n",
        "    page_num = 1\n",
        "\n",
        "    while True:\n",
        "        url = f\"{base_url}catalogue/page-{page_num}.html\"\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching page {page_num}: {e}\")\n",
        "            break\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "        if not books:\n",
        "            break\n",
        "        for book in books:\n",
        "            title = book.h3.a['title']\n",
        "            price = book.find('p', class_='price_color').text.strip()\n",
        "            availability = book.find('p', class_='instock availability').text.strip()\n",
        "            star_rating = book.find('p', class_='star-rating')['class'][1]\n",
        "\n",
        "            all_books_data.append({\n",
        "                'Title': title,\n",
        "                'Price': price,\n",
        "                'Availability': availability,\n",
        "                'Star Rating': star_rating\n",
        "            })\n",
        "\n",
        "        page_num += 1\n",
        "\n",
        "    return all_books_data\n",
        "\n",
        "books_data = scrape_books()\n",
        "\n",
        "df = pd.DataFrame(books_data)\n",
        "\n",
        "df.to_csv('books.csv', index=False)\n",
        "\n",
        "print(\"Scraping complete. Data saved to books.csv\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Write a Python program to scrape the IMDB Top 250 Movies list (https://www.imdb.com/chart/top/) . For each movie, extract the following details:\n",
        "1. Rank (1–250)\n",
        "2. Movie Title\n",
        "3. Year of Release\n",
        "4. IMDB Rating\n",
        "######Store the results in a Pandas DataFrame and export it to a CSV file named imdb_top250.csv.\n",
        "(Note: Use Selenium/Playwright to scrape the required details from this website)"
      ],
      "metadata": {
        "id": "C3IJ5Kzl4Z73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "\n",
        "# Configure Selenium options\n",
        "chrome_opts = Options()\n",
        "chrome_opts.add_argument(\"--headless\")\n",
        "chrome_opts.add_argument(\"--no-sandbox\")\n",
        "chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Spoof user-agent to avoid 403 Forbidden\n",
        "chrome_opts.add_argument(\n",
        "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "    \"Chrome/115.0.0.0 Safari/537.36\"\n",
        ")\n",
        "\n",
        "# Launch browser\n",
        "browser = webdriver.Chrome(options=chrome_opts)\n",
        "\n",
        "# Open IMDb Top 250\n",
        "browser.get(\"https://www.imdb.com/chart/top/\")\n",
        "time.sleep(5)  # wait for page to load\n",
        "\n",
        "film_list = []\n",
        "movie_cards = browser.find_elements(By.CSS_SELECTOR, \".ipc-metadata-list-summary-item\")\n",
        "\n",
        "# Extract movie details\n",
        "for rank, card in enumerate(movie_cards, start=1):\n",
        "    try:\n",
        "        name = card.find_element(By.CSS_SELECTOR, \"h3\").text\n",
        "        release_year = card.find_element(By.CSS_SELECTOR, \".cli-title-metadata-item\").text\n",
        "        score = card.find_element(By.CSS_SELECTOR, \".ipc-rating-star--imdb\").text.split()[0]\n",
        "        film_list.append([rank, name, release_year, score])\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping a card due to error: {e}\")\n",
        "\n",
        "browser.quit()\n",
        "\n",
        "# Save as DataFrame\n",
        "imdb_table = pd.DataFrame(film_list, columns=[\"Position\", \"Movie\", \"Release Year\", \"Rating\"])\n",
        "imdb_table.to_csv(\"imdb_top250.csv\", index=False)\n",
        "print(imdb_table.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmm5PF0n5L2V",
        "outputId": "d8f18fd6-c725-43ea-92a6-a8b25d293909"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Position                        Movie Release Year Rating\n",
            "0         1  1. The Shawshank Redemption         1994    9.3\n",
            "1         2             2. The Godfather         1972    9.2\n",
            "2         3           3. The Dark Knight         2008    9.1\n",
            "3         4     4. The Godfather Part II         1974    9.0\n",
            "4         5              5. 12 Angry Men         1957    9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Write a Python program to scrape the weather information for top world cities from the given website (https://www.timeanddate.com/weather/) . For each city, extract the following details:\n",
        "1. City Name\n",
        "2. Temperature\n",
        "3. Weather Condition (e.g., Clear, Cloudy, Rainy, etc.)\n",
        "\n",
        "Store the results in a Pandas DataFrame and export it to a CSV file named weather.csv.**bold text**"
      ],
      "metadata": {
        "id": "UGxogODy5sJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gives only 4"
      ],
      "metadata": {
        "id": "G4zuFMdWC2MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_weather(url, max_cities=None):\n",
        "    \"\"\"\n",
        "    Scrape weather data from timeanddate.com/weather/\n",
        "\n",
        "    Args:\n",
        "        url (str): URL to scrape\n",
        "        max_cities (int, optional): stop after this many cities. None = all.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: with columns City, Temperature, Condition\n",
        "    \"\"\"\n",
        "    resp = requests.get(url)\n",
        "    resp.raise_for_status()\n",
        "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "    data = []\n",
        "\n",
        "\n",
        "\n",
        "    section = soup.find('section', attrs={'id': 'qlook'})\n",
        "\n",
        "    city_links = soup.select('a[href^=\"/weather/\"]')\n",
        "\n",
        "    seen = set()\n",
        "    for link in city_links:\n",
        "        city = link.get_text().strip()\n",
        "        href = link.get('href')\n",
        "        if not href:\n",
        "            continue\n",
        "\n",
        "        if city in seen:\n",
        "            continue\n",
        "        seen.add(city)\n",
        "\n",
        "\n",
        "        temp = None\n",
        "        cond = None\n",
        "\n",
        "\n",
        "        parent = link.parent\n",
        "        if parent:\n",
        "            texts = parent.stripped_strings\n",
        "            for t in texts:\n",
        "                if '°' in t:\n",
        "                    temp = t.strip()\n",
        "                    break\n",
        "            img = parent.find('img')\n",
        "            if img:\n",
        "                cond = img.get('alt') or img.get('title')\n",
        "            if not cond:\n",
        "                for t in texts:\n",
        "                    low = t.strip().lower()\n",
        "                    if any(word in low for word in [\"cloud\", \"sun\", \"rain\", \"clear\", \"storm\", \"overcast\", \"haze\", \"fog\", \"drizzle\", \"thunder\", \"snow\"]):\n",
        "                        if t.strip() != temp:\n",
        "                            cond = t.strip()\n",
        "                            break\n",
        "\n",
        "\n",
        "        if temp is None or cond is None:\n",
        "            continue\n",
        "\n",
        "        data.append({'City': city, 'Temperature': temp, 'Condition': cond})\n",
        "\n",
        "        if max_cities is not None and len(data) >= max_cities:\n",
        "            break\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    url = 'https://www.timeanddate.com/weather/'\n",
        "    df = scrape_weather(url, max_cities=50)\n",
        "    print(df.head())\n",
        "    df.to_csv('weather1.csv', index=False)\n",
        "    print(\"Saved to weather.csv\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFB3UkDX9JTr",
        "outputId": "96d95dd5-afea-45b1-8e82-7dc7244437cd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            City Temperature                 Condition\n",
            "0                      67 °F            Mostly cloudy.\n",
            "1  Washington DC       67 °F            Mostly cloudy.\n",
            "2       New York       63 °F                    Clear.\n",
            "3         London       59 °F         Scattered clouds.\n",
            "4          Tokyo       77 °F  Sprinkles. Partly sunny.\n",
            "Saved to weather.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "47 alphabetically"
      ],
      "metadata": {
        "id": "41tLYmh0C5Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_timeanddate_top_cities(url=\"https://www.timeanddate.com/weather/\", max_cities=None):\n",
        "    \"\"\"\n",
        "    Scrape city, temperature, weather condition from timeanddate.com/weather/\n",
        "    :param url: URL to scrape.\n",
        "    :param max_cities: Maximum number of cities to scrape (None = all).\n",
        "    :return: list of dicts with keys: City, Temperature, Condition\n",
        "    \"\"\"\n",
        "    resp = requests.get(url)\n",
        "    resp.raise_for_status()\n",
        "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "    results = []\n",
        "\n",
        "\n",
        "    table = soup.find('table', attrs={'id': 'wt-48'})\n",
        "    if table is None:\n",
        "        table = soup.find('table')\n",
        "    if table is None:\n",
        "        raise RuntimeError(\"Could not find the weather table on the page\")\n",
        "\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        header = row.find('th')\n",
        "        if header:\n",
        "            continue\n",
        "\n",
        "        cols = row.find_all('td')\n",
        "        if len(cols) < 3:\n",
        "            continue\n",
        "\n",
        "        city_td = cols[0]\n",
        "        city_name = city_td.get_text(strip=True)\n",
        "\n",
        "\n",
        "        temp_td = None\n",
        "        for td in cols:\n",
        "            text = td.get_text(strip=True)\n",
        "            if text.endswith(\"°C\") or text.endswith(\"°F\"):\n",
        "                temp_td = td\n",
        "                break\n",
        "        if not temp_td:\n",
        "            continue\n",
        "        temperature = temp_td.get_text(strip=True)\n",
        "\n",
        "\n",
        "        condition = None\n",
        "\n",
        "        img = row.find('img')\n",
        "        if img and img.has_attr('alt'):\n",
        "            condition = img['alt'].strip()\n",
        "        if not condition:\n",
        "            for td in cols:\n",
        "                txt = td.get_text(\" \", strip=True)\n",
        "                if any(word in txt.lower() for word in ['clear','cloudy','rain','sunny','overcast','snow','fog','haze','storm','thunder']):\n",
        "                    if not txt.endswith(\"°C\") and not txt.endswith(\"°F\"):\n",
        "                        condition = txt\n",
        "                        break\n",
        "        if not condition:\n",
        "            condition = \"\"\n",
        "\n",
        "        results.append({\n",
        "            'City': city_name,\n",
        "            'Temperature': temperature,\n",
        "            'Condition': condition\n",
        "        })\n",
        "\n",
        "        if max_cities is not None and len(results) >= max_cities:\n",
        "            break\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    data = scrape_timeanddate_top_cities(max_cities=50)\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['City', 'Temperature', 'Condition'])\n",
        "\n",
        "    df.to_csv('weather2.csv', index=False)\n",
        "    print(\"Saved to weather.csv with {} entries\".format(len(df)))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBgoJ7FfA236",
        "outputId": "78e37286-1b0d-4958-ad32-5e044792b9d6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to weather.csv with 47 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "top 15 but visiting every single city's url"
      ],
      "metadata": {
        "id": "68TxXyIMC8o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Mapping of city names to their timeanddate URLs\n",
        "CITY_URLS = {\n",
        "    \"New York City\": \"https://www.timeanddate.com/weather/usa/new-york\",\n",
        "    \"London\": \"https://www.timeanddate.com/weather/uk/london\",\n",
        "    \"Tokyo\": \"https://www.timeanddate.com/weather/japan/tokyo\",\n",
        "    \"Paris\": \"https://www.timeanddate.com/weather/france/paris\",\n",
        "    \"Singapore\": \"https://www.timeanddate.com/weather/singapore/singapore\",\n",
        "    \"Dubai\": \"https://www.timeanddate.com/weather/united-arab-emirates/dubai\",\n",
        "    \"Sydney\": \"https://www.timeanddate.com/weather/australia/sydney\",\n",
        "    \"Hong Kong\": \"https://www.timeanddate.com/weather/hong-kong/hong-kong\",\n",
        "    \"Los Angeles\": \"https://www.timeanddate.com/weather/usa/los-angeles\",\n",
        "    \"Beijing\": \"https://www.timeanddate.com/weather/china/beijing\",\n",
        "    \"Moscow\": \"https://www.timeanddate.com/weather/russia/moscow\",\n",
        "    \"Rome\": \"https://www.timeanddate.com/weather/italy/rome\",\n",
        "    \"Chicago\": \"https://www.timeanddate.com/weather/usa/chicago\",\n",
        "    \"Toronto\": \"https://www.timeanddate.com/weather/canada/toronto\",\n",
        "    \"Shanghai\": \"https://www.timeanddate.com/weather/china/shanghai\"\n",
        "}\n",
        "\n",
        "def scrape_city_weather(city, url):\n",
        "    \"\"\"Scrape weather info (temperature, condition) for a single city.\"\"\"\n",
        "    resp = requests.get(url)\n",
        "    resp.raise_for_status()\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "    temp_div = soup.find(\"div\", id=\"qlook\")\n",
        "    temperature = temp_div.find(\"div\", class_=\"h2\").get_text(strip=True) if temp_div else \"\"\n",
        "\n",
        "    condition = \"\"\n",
        "    if temp_div:\n",
        "        cond_span = temp_div.find(\"p\")\n",
        "        if cond_span:\n",
        "            condition = cond_span.get_text(strip=True)\n",
        "\n",
        "    return {\n",
        "        \"City\": city,\n",
        "        \"Temperature\": temperature,\n",
        "        \"Condition\": condition\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    results = []\n",
        "    for city, url in CITY_URLS.items():\n",
        "        print(f\"Scraping {city}...\")\n",
        "        try:\n",
        "            results.append(scrape_city_weather(city, url))\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to scrape {city}: {e}\")\n",
        "            results.append({\"City\": city, \"Temperature\": \"\", \"Condition\": \"\"})\n",
        "\n",
        "    df = pd.DataFrame(results, columns=[\"City\", \"Temperature\", \"Condition\"])\n",
        "\n",
        "    df.to_csv(\"weather3.csv\", index=False)\n",
        "    print(\"Saved weather info for all 15 cities to weather3.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcF_JJmsBvzD",
        "outputId": "23722d53-70d6-4164-f8ce-e34b186519f9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping New York City...\n",
            "Scraping London...\n",
            "Scraping Tokyo...\n",
            "Scraping Paris...\n",
            "Scraping Singapore...\n",
            "Scraping Dubai...\n",
            "Scraping Sydney...\n",
            "Scraping Hong Kong...\n",
            "Scraping Los Angeles...\n",
            "Scraping Beijing...\n",
            "Scraping Moscow...\n",
            "Scraping Rome...\n",
            "Scraping Chicago...\n",
            "Scraping Toronto...\n",
            "Scraping Shanghai...\n",
            "Saved weather info for all 15 cities to weather3.csv\n"
          ]
        }
      ]
    }
  ]
}